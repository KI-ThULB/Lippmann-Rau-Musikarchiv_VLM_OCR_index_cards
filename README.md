# Lippmann-Rau-Musikarchiv_VLM_OCR_index_cards
> Automated metadata extraction from ~43,000 digitized archive index cards using Vision Language Models (Qwen VL)

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

[![Qwen VL](https://img.shields.io/badge/Model-Qwen%20VL-red.svg)](https://github.com/QwenLM/Qwen-VL)

## ğŸ“‹ Overview

This project automates the digitization of the **Lippmann-Rau Music Archive** in Eisenach, Germany. It processes 86 batch folders containing approximately 43,000 historical index cards, extracting structured metadata using state-of-the-art Vision Language Models.

### Key Features

- ğŸš€ **Parallel Processing** - Multi-threaded batch processing with configurable workers
- ğŸ’¾ **Robust Checkpointing** - Resume from interruption at file and batch level
- ğŸ“Š **Comprehensive Analysis** - Built-in quality assessment and statistics
- ğŸ”„ **Automatic CSV Merging** - Combines all batch outputs into a single master file
- ğŸ›¡ï¸ **Error Handling** - Exponential backoff retry logic with detailed error logging
- ğŸ¯ **Flexible Configuration** - Easily adaptable for different archive structures

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Input: 86 Batch Folders                   â”‚
â”‚                   (~500 index cards each)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-Batch OCR Processor                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ Parallel Workers (5-10 threads)                   â”‚   â”‚
â”‚  â”‚  â€¢ Qwen3-VL / Qwen2.5-VL API Integration            â”‚   â”‚
â”‚  â”‚  â€¢ Checkpoint System (file + batch level)           â”‚   â”‚
â”‚  â”‚  â€¢ Retry Logic with Exponential Backoff             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Output                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  86 Batch    â”‚   JSON       â”‚  Master CSV            â”‚   â”‚
â”‚  â”‚  CSVs        â”‚   Archives   â”‚  (43,000+ entries)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8 or higher
python3 --version

# Required packages
pip install pandas requests
```

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/lippmann-rau-ocr.git
cd lippmann-rau-ocr

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Edit `Lippmann-Rau_VLM_OCR_MultiBatch.py`:

```python
# Line 22-23: Set your input directory
BASE_INPUT_DIR = "/path/to/your/JPEG/batches"

# Line 27: Batch folder pattern
BATCH_PATTERN = "Batch_*"  # or "*" for all subdirectories

# Line 34: Choose your model
MODEL_NAME = "qwen3-vl:8b"          # Recommended: Best OCR
# MODEL_NAME = "qwen2.5vl:32b"      # Alternative: Tested & stable
# MODEL_NAME = "qwen3-vl:32b"       # Best quality (slower)

# Line 39: Performance tuning
MAX_WORKERS = 5  # Adjust based on your server capacity
```

### Usage

```bash
# Start the multi-batch processing
python3 Lippmann-Rau_VLM_OCR_MultiBatch.py

# Enter your API key when prompted
# The script will process all 86 batches automatically

# After completion, analyze results
python3 analyze_results.py
```

## ğŸ“ Project Structure

```
lippmann-rau-ocr/
â”œâ”€â”€ Lippmann-Rau_VLM_OCR_MultiBatch.py    # Main processing script
â”œâ”€â”€ analyze_results.py                     # Analysis & quality reports
â”œâ”€â”€ merge_csvs.py                          # Manual CSV merger (backup)
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ CHANGES.md                             # Changelog & migration guide
â””â”€â”€ output_batches/                        # Output directory (created)
    â”œâ”€â”€ csv/                               # Individual batch CSVs
    â”‚   â”œâ”€â”€ Batch_001.csv
    â”‚   â”œâ”€â”€ Batch_002.csv
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ json/                              # JSON archives by batch
    â”‚   â”œâ”€â”€ Batch_001/
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ metadata_vlm_complete.csv          # ğŸ¯ Master output file
    â”œâ”€â”€ analysis/                          # Analysis reports
    â”‚   â”œâ”€â”€ field_completeness.csv
    â”‚   â”œâ”€â”€ batch_statistics.csv
    â”‚   â”œâ”€â”€ komponisten_frequency.csv
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ batch_progress.json                # Progress tracking
    â””â”€â”€ vlm_errors.log                     # Error log
```

## ğŸ“Š Extracted Metadata Fields

Each index card is parsed into the following structured fields:

| Field | Description | Example |
|-------|-------------|---------|
| **Datei** | Filename | `karte_12345.jpg` |
| **Batch** | Batch folder | `Batch_042` |
| **Komponist** | Composer name | `Zimmermann, Rolf` |
| **Signatur** | Archive signature | `Spez.12.433` |
| **Titel** | Work title | `Sonate fÃ¼r Violine` |
| **Textanfang** | Text incipit | `Es war einmal...` |
| **Verlag** | Publisher | `Peters Leipzig` |
| **Material** | Material type | `1 Part. u. Stimmen` |
| **Textdichter** | Lyricist | `Goethe, Johann W.` |
| **Bearbeiter** | Arranger | `MÃ¼ller, Hans` |
| **Bemerkungen** | Remarks | `Handschriftlich` |

## ğŸ¯ Performance Benchmarks

### Processing Speed

| Configuration | Model | Speed | Total Time (43k cards) |
|--------------|-------|-------|----------------------|
| 5 workers | Qwen3-VL-8B | ~150 cards/hour | 24-36 hours |
| 10 workers | Qwen3-VL-8B | ~250 cards/hour | 15-20 hours |
| 5 workers | Qwen2.5-VL-32B | ~100 cards/hour | 36-48 hours |

*Note: Actual speed depends on API response time and network stability*

### Quality Metrics

Based on test runs:
- âœ… **Success Rate**: 95-98%
- ğŸ“ **Komponist Extraction**: 85-92%
- ğŸ”– **Signatur Extraction**: 88-94%
- âœ“ **Valid Signatur Format**: 90-96%

## ğŸ”§ Advanced Configuration

### Model Selection

```python
# Qwen3-VL-8B (Recommended)
# âœ… Best OCR performance (32 languages)
# âœ… Fast processing
# âœ… Excellent handwriting recognition
MODEL_NAME = "qwen3-vl:8b"

# Qwen2.5-VL-32B
# âœ… Well-tested and stable
# âœ… Good for structured documents
# âš ï¸ Slower than 8B variant
MODEL_NAME = "qwen2.5vl:32b"

# Qwen3-VL-32B
# âœ… Highest quality
# âš ï¸ Slowest processing
MODEL_NAME = "qwen3-vl:32b"
```

### Performance Tuning

```python
# For fast server with stable API
MAX_WORKERS = 10
MAX_RETRIES = 2
RETRY_DELAY = 2

# For slow/unstable connection
MAX_WORKERS = 3
MAX_RETRIES = 5
RETRY_DELAY = 5
```

### Batch Folder Patterns

```python
# Pattern 1: "Batch_001", "Batch_002", ...
BATCH_PATTERN = "Batch_*"

# Pattern 2: "001", "002", "003", ...
BATCH_PATTERN = "[0-9][0-9][0-9]"

# Pattern 3: All subdirectories
BATCH_PATTERN = "*"
```

## ğŸ“ˆ Workflow

### Phase 1: Testing (Day 1)
```bash
# Process 1-2 test batches
python3 Lippmann-Rau_VLM_OCR_MultiBatch.py
# Press Ctrl+C after 1-2 batches

# Analyze test results
python3 analyze_results.py

# Review output CSV for quality
```

### Phase 2: Full Processing (Day 2-3)
```bash
# Start full batch processing
python3 Lippmann-Rau_VLM_OCR_MultiBatch.py
# Let run overnight (24-36 hours)
```

### Phase 3: Analysis (Day 4)
```bash
# Generate comprehensive statistics
python3 analyze_results.py

# Review analysis reports in output_batches/analysis/
# - field_completeness.csv
# - batch_statistics.csv
# - komponisten_frequency.csv
# - problematic_cards.csv
# - missing_signatures.csv
```

## ğŸ›¡ï¸ Error Handling & Recovery

### Checkpoint System

The script maintains two levels of checkpoints:

1. **File-level checkpoints**: Tracks processed cards within each batch
2. **Batch-level progress**: Tracks completed batches

On interruption (Ctrl+C or crash):
- âœ… Already processed files are skipped
- âœ… Completed batches are not reprocessed
- âœ… Processing resumes automatically from last position

### Retry Logic

```python
# Automatic retry with exponential backoff
MAX_RETRIES = 3           # 3 attempts per card
RETRY_DELAY = 2           # Initial delay: 2s
# Backoff: 2s â†’ 4s â†’ 6s
```

### Error Logging

All errors are logged to `output_batches/vlm_errors.log`:
```
[2025-10-30T12:34:56] Batch: Batch_042 | Datei: card_12345.jpg
âš ï¸  API timeout after 120s
Details: Connection timeout
----------------------------------------------------------------
```

## ğŸ“Š Analysis Tools

### Built-in Analysis (`analyze_results.py`)

Generates comprehensive reports:

```bash
python3 analyze_results.py
```

**Output:**
- Field completeness statistics
- Batch-by-batch comparison
- Top composers ranking
- Signature pattern analysis
- Quality metrics (empty/sparse/complete records)
- Problematic cards identification

### Manual CSV Merging (`merge_csvs.py`)

Backup tool for manual CSV combination:

```bash
python3 merge_csvs.py [optional_csv_directory]
```

## ğŸ”’ Security

### API Key Management

**Current (Recommended):**
```bash
# API key is requested securely at runtime
python3 Lippmann-Rau_VLM_OCR_MultiBatch.py
# â†’ API-Key: [hidden input]
```

**Alternative (Environment Variable):**
```bash
# Add to script configuration
import os
API_KEY = os.getenv('QWEN_API_KEY')

# Terminal
export QWEN_API_KEY="sk-..."
python3 Lippmann-Rau_VLM_OCR_MultiBatch.py
```

âš ï¸ **Never commit API keys to Git!** Use `.gitignore`:
```
# .gitignore
*.env
.env
api_key.txt
config_local.py
```

## ğŸ› Troubleshooting

### Common Issues

**Issue: "No batch folders found"**
```bash
# Solution 1: Check BASE_INPUT_DIR path
# Solution 2: Adjust BATCH_PATTERN
# Solution 3: Test manually:
python3 -c "from pathlib import Path; print(list(Path('/your/path').glob('*')))"
```

**Issue: API errors or timeouts**
```python
# Solution: Reduce MAX_WORKERS
MAX_WORKERS = 3

# Increase retry delay
RETRY_DELAY = 5
```

**Issue: Poor OCR quality**
```python
# Solution 1: Switch to Qwen3-VL
MODEL_NAME = "qwen3-vl:8b"

# Solution 2: Adjust temperature
"temperature": 0.0  # More consistent (in call_vlm_api function)

# Solution 3: Check image quality
# Recommended: 300 DPI or higher
```

**Issue: Interrupted processing**
```bash
# Simply restart - checkpoints ensure continuation
python3 Lippmann-Rau_VLM_OCR_MultiBatch.py
```

## ğŸ“ Citation

If you use this project in academic work, please cite:

```bibtex
@software{lippmann_rau_ocr_2025,
  title = {Lippmann-Rau Archive OCR: Automated Metadata Extraction from Historical Index Cards},
  author = {Tom MeiÃŸner},
  year = {2025},
  url = {https://github.com/your-username/lippmann-rau-ocr}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Development Setup

```bash
# Clone repository
git clone https://github.com/your-username/lippmann-rau-ocr.git
cd lippmann-rau-ocr

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

## ğŸ“„ License

This project is licensed under CC-BY 4.0

## ğŸ“ Contact

**Project Maintainer:** Tom MeiÃŸner
- Email: tom.meissner@uni-jena.de
- GitHub: [ki_thulb](https://github.com/ki_thulb)


## ğŸ“Š Project Status

**Current Version:** 1.0.0  
**Status:** beta / testing  
**Last Updated:** October 2025

### Roadmap

- [x] Multi-batch processing
- [x] Checkpoint system
- [x] Analysis tools
- [x] Error handling
- [ ] Web interface for quality control
- [ ] Export to library catalog formats (MARC, Dublin Core)
- [ ] Integration with archive management systems
- [ ] Machine learning model fine-tuning on archive-specific cards
